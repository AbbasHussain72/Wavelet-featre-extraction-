{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN83+h8EhIiTV3yshdmMx3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbbasHussain72/Wavelet-featre-extraction-/blob/main/CNN_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bENSS1n6SpYa"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from matplotlib.widgets import SpanSelector\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Activation, Dense, Dropout, Flatten,Conv1D,MaxPooling1D,concatenate\n",
        "from keras.models import load_model,Model\n",
        "from keras.utils import to_categorical , plot_model\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib import font_manager as fm, pyplot as plt\n",
        "!wget https://github.com/trishume/OpenTuringCompiler/blob/master/stdlib-sfml/fonts/Times%20New%20Roman.ttf\n",
        "!wget https://github.com/matomo-org/travis-scripts/blob/master/fonts/Arial.ttf\n",
        "font_files = fm.findSystemFonts()\n",
        "# Go through and add each to Matplotlib's font cache.\n",
        "for font_file in font_files:\n",
        "    fm.fontManager.addfont(font_file)\n",
        "# Use your new font on all your plots.\n",
        "plt.rc('font', family='serif ')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install scikeras"
      ],
      "metadata": {
        "id": "vGo2fP6PbkRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04pfKILYS2fO",
        "outputId": "6eb35c62-7d84-4486-fc58-4b21fb46f33c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read datafile and reset index\n",
        "path = '/content/drive/MyDrive/50L3_wfeature.csv'\n",
        "df = pd.read_csv(path,sep='\\t')\n",
        "df = df.drop(['Unnamed: 0'], axis = 1)\n",
        "\n",
        "#read wavelet names file\n",
        "path = '/content/drive/MyDrive/wavelet_names.csv'\n",
        "md = pd.read_csv(path,sep=',')\n",
        "wavelets= md['Wavelets'].tolist()"
      ],
      "metadata": {
        "id": "HZSUHi-yTGMe"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.head()"
      ],
      "metadata": {
        "id": "EI7tmQJjUR6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('X_train_reshaped: ', X_train_reshaped.shape)\n",
        "# print('X_test_reshaped: ', X_test_reshaped.shape)\n",
        "\n",
        "# print('y_train_encode : ', y_train_encode.shape)\n",
        "# print('y_test: ', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dekicYTWNiQB",
        "outputId": "bad7e572-1903-43f1-a97a-d1a232e085f8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_reshaped:  (1453, 55, 1)\n",
            "X_test_reshaped:  (624, 55, 1)\n",
            "y_train_encode :  (1453,)\n",
            "y_test:  (624,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #To check the unique value\n",
        "# unique_values_train = np.unique(y_train_encode)\n",
        "# unique_values_test = np.unique(y_test)\n",
        "# print(\"Unique values in y_train:\", unique_values_train)\n",
        "# print(\"Unique values in y_test:\", unique_values_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AUdS7oCg-91",
        "outputId": "23ef22b2-2bd4-4ce0-9d35-df05fcce83c4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in y_train: [0 1 2 3 4 5 6 7 8 9]\n",
            "Unique values in y_test: ['OP01bad' 'OP01good' 'OP02bad' 'OP02good' 'OP04bad' 'OP04good' 'OP07bad'\n",
            " 'OP07good' 'OP10bad' 'OP10good']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN model"
      ],
      "metadata": {
        "id": "A2uvwh8MNNjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=(55, 1)))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))  # Assuming 10 classes\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "CoTrFHqaflL9"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "BzBoq7Agty2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyvJ1usUvyx2",
        "outputId": "1b41da66-0902-402f-9ff9-253236691d59"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invert the class labels using the inverse_transform method\n",
        "y_pred_original_labels = label_encoder.inverse_transform(y_pred_labels)"
      ],
      "metadata": {
        "id": "gtHUgBv4vrrd"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_pred_original_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWNYsZXDwUp-",
        "outputId": "904ab54a-5f3f-4c1a-d0aa-5bbc99e01c22"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['OP01bad', 'OP01good', 'OP02bad', 'OP02good', 'OP04bad',\n",
              "       'OP04good', 'OP07bad', 'OP07good', 'OP10bad', 'OP10good'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning Using gridsearch"
      ],
      "metadata": {
        "id": "IXlkFjFvEGz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wavelets"
      ],
      "metadata": {
        "id": "GKwWK6uHE5bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wavelets1 = wavelets[0:15]\n",
        "wavelets1"
      ],
      "metadata": {
        "id": "vm9RvLJtr2qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate data through each wavelet\n",
        "\n",
        "# Create an empty DataFrame to store results\n",
        "columns = ['wavelet', 'drop_rate', 'kernel_size', 'learning_rate', 'num_filters', 'val_f1_score']\n",
        "df_results = pd.DataFrame(columns=columns)\n",
        "\n",
        "f1_scores_list = []\n",
        "\n",
        "for w in wavelets1:\n",
        "  print(f\"\\nProcessing for wavelet: {w}\")\n",
        "  start_time = time.time()\n",
        "  new = df[df['wavelet'] == w]\n",
        "  # print (new.shape)\n",
        "  X = new.drop(['Date', 'Machine', 'Operation', 'Condition', 'Repeat', 'operationcondition', 'wavelet'], axis=1)\n",
        "  y = new['operationcondition']\n",
        "  print (w)\n",
        "  #Train_Test split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  # # Create for feature selection\n",
        "  f_selection = RandomForestClassifier(random_state = 42, verbose=0)\n",
        "  # Perform feature selection using SelectFromModel\n",
        "  feature_selector = SelectFromModel(f_selection)\n",
        "  feature_selector.fit(X_train, y_train)\n",
        "  X_train_transformed = feature_selector.transform(X_train)\n",
        "  X_test_transformed = feature_selector.transform(X_test)\n",
        "\n",
        "  # Perform standardscalar transformation\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train_transformed)\n",
        "  X_test_scaled = scaler.transform(X_test_transformed)\n",
        "\n",
        "  #Label Encoding for CNN\n",
        "  label_encoder = LabelEncoder()\n",
        "  y_train_encode = label_encoder.fit_transform(y_train)\n",
        "\n",
        "  # Reshape the data for a 1D CNN\n",
        "  X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "  X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "  inputshape = (X_train_scaled.shape[1],1)\n",
        "\n",
        "  def create_model(num_filters=64, kernel_size=3, dropout_rate=0.5, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(num_filters, kernel_size, activation='relu', input_shape= inputshape ))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))  # Add dropout here with the specified rate\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "  # Wrap the Keras model for use with scikit-learn\n",
        "  keras_model = KerasClassifier(build_fn=create_model,num_filters=16,learning_rate=0.001, dropout_rate=0.2,kernel_size=3, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "  # Define the parameter grid for grid search\n",
        "  param_grid = {\n",
        "    'num_filters': [16, 32, 64],\n",
        "    'kernel_size': [3, 5,7],\n",
        "    'dropout_rate': [0.2, 0.5, 0.8],\n",
        "    'learning_rate': [0.001, 0.01,0.1]}\n",
        "\n",
        "  # Create GridSearchCV instance\n",
        "  grid_search = GridSearchCV(estimator=keras_model, param_grid=param_grid, verbose = 0,\n",
        "                          scoring='f1_macro', cv=3, n_jobs=-1)\n",
        "\n",
        "\n",
        "  # Fit the grid search to your data\n",
        "  grid_search.fit(X_train_reshaped, y_train_encode)\n",
        "\n",
        "  # print(f'Best hyperparameters for {w}: {grid_search.best_params_}')\n",
        "  # print(f'Best hyperparameters for {w}: {grid_search.best_score_}')\n",
        "\n",
        "  # Extract best parameters and score\n",
        "  best_params = grid_search.best_params_\n",
        "  best_score = grid_search.best_score_\n",
        "\n",
        "  # Add a row with values to the DataFrame\n",
        "  df_results = df_results.append({\n",
        "        'wavelet': w,\n",
        "        'drop_rate': best_params['dropout_rate'],\n",
        "        'kernel_size': best_params['kernel_size'],\n",
        "        'learning_rate': best_params['learning_rate'],\n",
        "        'num_filters': best_params['num_filters'],\n",
        "        'f1_score': best_score\n",
        "    }, ignore_index=True)\n",
        "\n",
        "  # Save the DataFrame to a CSV file after each iteration\n",
        "  df_results.to_csv('/content/drive/MyDrive/CNNl3_bestparascore.csv', sep='\\t', index=False)\n",
        "\n",
        "\n",
        "  # Prediction on the test set\n",
        "  y_pred = grid_search.predict(X_test_reshaped)\n",
        "\n",
        "  # # Reshape y_pred if needed\n",
        "  # if y_pred.ndim == 1:\n",
        "  #     y_pred = y_pred.reshape(-1, 1)\n",
        "\n",
        "  # y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "  y_pred_original_labels = label_encoder.inverse_transform(y_pred)\n",
        "  end_time = time.time()\n",
        "\n",
        "  #Evaluation on f1score\n",
        "  f1_test = f1_score(y_test,y_pred_original_labels,average='macro')\n",
        "  print(end_time-start_time)\n",
        "  # print(f'F1 score on test set for {w}: {f1_test}')\n",
        "\n",
        "  # Save the F1 score for the current wavelet to the list\n",
        "  f1_scores_list.append({'wavelet': w, 'f1_score': f1_test})\n",
        "\n",
        "# Save the final data frame to a CSV file\n",
        "df_results.to_csv('/content/drive/MyDrive/CNNl3_bestparascore_final.csv', sep='\\t', index=False)\n",
        "\n",
        "# Create the DataFrame outside the loop\n",
        "df_f1_scores = pd.DataFrame(f1_scores_list)\n",
        "# Save the DataFrame to a CSV file\n",
        "df_f1_scores.to_csv('/content/drive/MyDrive/CNNl3f1scores_final.csv', sep='\\t', index=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZtiqTFJTeco",
        "outputId": "ef28b290-a048-43f7-881a-ca06b9ad57f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing for wavelet: db2\n",
            "db2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "<ipython-input-133-b0cea9a867d6>:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_results = df_results.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363.4583203792572\n",
            "\n",
            "Processing for wavelet: db3\n",
            "db3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "<ipython-input-133-b0cea9a867d6>:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_results = df_results.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "353.65211629867554\n",
            "\n",
            "Processing for wavelet: db4\n",
            "db4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "<ipython-input-133-b0cea9a867d6>:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_results = df_results.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339.3931233882904\n",
            "\n",
            "Processing for wavelet: db5\n",
            "db5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "<ipython-input-133-b0cea9a867d6>:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_results = df_results.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "346.9253628253937\n",
            "\n",
            "Processing for wavelet: db6\n",
            "db6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "<ipython-input-133-b0cea9a867d6>:84: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_results = df_results.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "345.86429262161255\n",
            "\n",
            "Processing for wavelet: db7\n",
            "db7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfread = pd.read_csv('/content/drive/MyDrive/CNNl3f1scores.csv',sep='\\t')"
      ],
      "metadata": {
        "id": "hSlNg-rOkHYj"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "-GoGpqbTkS8j",
        "outputId": "bfcec1de-20bc-42f7-a1ec-4f8ae99466d1"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  wavelet  f1_score\n",
              "0    db10    0.9129"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63573511-28b3-4b8b-88df-1c73f8063586\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wavelet</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>db10</td>\n",
              "      <td>0.9129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63573511-28b3-4b8b-88df-1c73f8063586')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63573511-28b3-4b8b-88df-1c73f8063586 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63573511-28b3-4b8b-88df-1c73f8063586');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix for CNN"
      ],
      "metadata": {
        "id": "-AEuDOwqDhJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "y_test_pred = y_pred_original_labels\n",
        "test_confu_matrix = confusion_matrix(y_test,  y_test_pred)\n",
        "report = classification_report(y_test,  y_test_pred)\n",
        "# print(report)\n",
        "lines = report.split('\\n')   # Split the report into lines\n",
        "labels = [line.split()[0] for line in lines[2:12]]   # Extract the labels from each line"
      ],
      "metadata": {
        "id": "-_ZR63OXwTUI"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckr2SnMMB6zE",
        "outputId": "9496f964-a78c-45bb-cc33-46941cfe7f05"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     OP01bad       0.95      0.97      0.96        64\n",
            "    OP01good       0.85      0.94      0.89        53\n",
            "     OP02bad       1.00      0.89      0.94        65\n",
            "    OP02good       0.85      0.98      0.91        64\n",
            "     OP04bad       0.91      0.88      0.90        60\n",
            "    OP04good       0.82      0.84      0.83        49\n",
            "     OP07bad       0.90      0.96      0.93        76\n",
            "    OP07good       0.93      0.86      0.90        65\n",
            "     OP10bad       0.95      0.88      0.91        60\n",
            "    OP10good       0.95      0.88      0.92        68\n",
            "\n",
            "    accuracy                           0.91       624\n",
            "   macro avg       0.91      0.91      0.91       624\n",
            "weighted avg       0.92      0.91      0.91       624\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.DataFrame([row.split() for row in report.split('\\n')[2:-5]])"
      ],
      "metadata": {
        "id": "4fV54hW3CpeH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dd.head(10)"
      ],
      "metadata": {
        "id": "4c5g8eaHCr1j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}